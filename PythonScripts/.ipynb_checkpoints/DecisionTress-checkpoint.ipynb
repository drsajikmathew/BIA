{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Python modules\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas read_csv function to upload Bikebuyer data from the computer folder (Mac) to IPython. For other OS, please refer to Chapter 6 of Wes McKinney’s book on Python for Data Analysis\n",
    "\n",
    "data=pd.read_csv(\"/Users/sajimathew/Documents/DoMS/Teaching/EMBA/DMBI/DMBI-2020/Data/Bikebuyer.csv\")\n",
    "#Extract relevant features from data\n",
    "X=data[['MaritalStatus','YearlyIncome','TotalChildren','ChildrenAtHome','HouseOwnerFlag','NumberCarsOwned','Age']]\n",
    "#Convert ‘MartitalStatus’ to nominal data (M, F to 0, 1)\n",
    "X['MaritalStatus']=pd.get_dummies(X['MaritalStatus'])\n",
    "#Assign Bikebuyer as target variable y\n",
    "y=data['BikeBuyer']\n",
    "#Split X into train and test data: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "#Specify decision tree model as dt using scikit learn “DecisionTreeClassifier” module: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=800,\n",
    "    min_samples_leaf=500,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0)\n",
    "#Fit the model using fit() method\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining Cost Complexity Parameter (ccp_alpha) for post pruning the tree: https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py\n",
    "\n",
    "path = dt.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "#Using matplotlib.pyplot to plot the effect of varying ccp_alpha on error\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1],impurities[:-1],marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "plt.plot(ccp_alphas, impurities)\n",
    "\n",
    "dts = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dts.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluates prediction accuracy and plots it against ccp_alphas\n",
    "\n",
    "train_scores = [dt.score(X_train, y_train) for dt in dts]\n",
    "test_scores = [dt.score(X_test, y_test) for dt in dts]\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building final tree\n",
    "\n",
    "dt=DecisionTreeClassifier(criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=800,\n",
    "    min_samples_leaf=500,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0025)\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the tree using graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None,feature_names=X_train.columns,class_names=['NonBuyer','Buyer'],filled=True, rounded=True,special_characters=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred=dt.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn, fp, fn, tp\n",
    "print(classification_report(y_test, y_pred, target_names=['Buyer','Nonbuyer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "#Generates 1000 subsamples for tree\n",
    "dt=RandomForestClassifier(n_estimators=5, criterion='gini', \n",
    "                          max_depth=None, min_samples_split=800, \n",
    "                          min_samples_leaf=500, \t\n",
    "                          min_weight_fraction_leaf=0.0, \n",
    "                          max_features='auto', \n",
    "                          max_leaf_nodes=None, \n",
    "                          min_impurity_decrease=0.0, \n",
    "                          min_impurity_split=None, \n",
    "                          bootstrap=True, oob_score=False, \n",
    "                          n_jobs=None, \n",
    "                          random_state=None, verbose=0, \n",
    "                          warm_start=False, \n",
    "                          class_weight=None, ccp_alpha=0.0,\n",
    "                          max_samples=None)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred=dt.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn, fp, fn, tp\n",
    "print(classification_report(y_test, y_pred, target_names=['Buyer','Nonbuyer']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "\n",
    "#simple validation set approach: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter  \n",
    "#by default splits into five folds\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scores = cross_validate(dt, X_test, y_test)\n",
    "k=scores['test_score']\n",
    "k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=500)\n",
    "scores=[]\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index],y[train_index], y[test_index]\n",
    "    dt.fit(X_train, y_train)\n",
    "    scores.append(dt.score(X_test, y_test)) \n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
